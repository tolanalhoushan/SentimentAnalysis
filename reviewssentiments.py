# -*- coding: utf-8 -*-
"""ReviewsSentiments.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bg8TzqR5HLi0M_KtXvcSGe8GQFVH0TGi
"""

import os
import json
from zipfile import ZipFile
import pandas as pd
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Dense

kaggle=json.load(open("kaggle.json"))

os.environ["KAGGLE_USERNAME"]=kaggle["username"]
os.environ["KAGGLE_KEY"]=kaggle["key"]

!kaggle datasets download -d volodymyrgavrysh/imdb-sentiment-10k-reviews-binary-classification

!ls

with ZipFile("imdb-sentiment-10k-reviews-binary-classification.zip","r") as zip_ref:
  zip_ref.extractall()

!ls

df=pd.read_csv("imdb_10K_sentimnets_reviews.csv")
df.head()

df.shape

#counting pos and neg reviews
df["sentiment"].value_counts()

#spliting data
train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)

# Tokenize text data
tokenizer = Tokenizer(num_words=5000)
tokenizer.fit_on_texts(train_data["review"])
X_train = pad_sequences(tokenizer.texts_to_sequences(train_data["review"]), maxlen=200)
X_test = pad_sequences(tokenizer.texts_to_sequences(test_data["review"]), maxlen=200)

#training
Y_train = train_data["sentiment"]
Y_test = test_data["sentiment"]

print(Y_train)

# building the model
model = Sequential([
    Embedding(input_dim=5000, output_dim=128, input_length=200),
    LSTM(128, dropout=0.2, recurrent_dropout=0.2),
    Dense(1, activation="sigmoid")
])

model.build(input_shape=(None, 200))

model.summary()

#compiling
model.compile(optimizer="adam", loss="binary_crossentropy", metrics=["accuracy"])

model.fit(X_train, Y_train, epochs=5, batch_size=64, validation_split=0.2)

#evaluating the model
loss,accuracy=model.evaluate(X_test,Y_test)
print("loss",loss)
print("accuracy",accuracy)

# a function to predict the sentiments
def sentimentpred(review):
  #tokenizing the review text to sequences
  sequence = tokenizer.texts_to_sequences([review])
  padded_sequence = pad_sequences(sequence, maxlen=200)
  pred = model.predict(padded_sequence)
  sentiment = "positive" if pred[0][0] > 0.5 else "negative"
  return sentiment

new_review = "It was really long and boring, nothing special."
sentiment = sentimentpred(new_review)
print(f"The sentiment of the review is: {sentiment}")

new_review = "AMAZING. we really enjoyed this film"
sentiment = sentimentpred(new_review)
print(f"The sentiment of the review is: {sentiment}")

new_review = "what was that? was it suppose to be horror..."
sentiment = sentimentpred(new_review)
print(f"The sentiment of the review is: {sentiment}")